Path to Cutadapt set as: 'cutadapt' (default)
Cutadapt seems to be working fine (tested command 'cutadapt --version')
Cutadapt version: 4.8
Could not detect version of Python used by Cutadapt from the first line of Cutadapt (but found this: >>>#!/bin/sh<<<)
Letting the (modified) Cutadapt deal with the Python version instead
Parallel gzip (pigz) detected. Proceeding with multicore (de)compression using 2 cores

No quality encoding type selected. Assuming that the data provided uses Sanger encoded Phred scores (default)

Output will be written into the directory: /workspace/lab/mcarthurlab/nasirja/covid-19-signal/benchmark_output/sars-cov-2-failedQC_results_dir/benchmark-bad10/adapter_trimmed/


AUTO-DETECTING ADAPTER TYPE
===========================
Attempting to auto-detect adapter type from the first 1 million sequences of the first file (>> benchmark-bad10/host_removal/benchmark-bad10_R1.fastq.gz <<)

Found perfect matches for the following adapter sequences:
Adapter type	Count	Sequence	Sequences analysed	Percentage
Nextera	0	CTGTCTCTTATA	1481	0.00
Illumina	0	AGATCGGAAGAGC	1481	0.00
smallRNA	0	TGGAATTCTCGG	1481	0.00
Unable to auto-detect most prominent adapter from the first specified file (count Nextera: 0, count Illumina: 0, count smallRNA: 0)
Defaulting to Illumina universal adapter ( AGATCGGAAGAGC ). Specify -a SEQUENCE to avoid this behavior).

Writing report to '/workspace/lab/mcarthurlab/nasirja/covid-19-signal/benchmark_output/sars-cov-2-failedQC_results_dir/benchmark-bad10/adapter_trimmed/benchmark-bad10_R1.fastq.gz_trimming_report.txt'

SUMMARISING RUN PARAMETERS
==========================
Input filename: benchmark-bad10/host_removal/benchmark-bad10_R1.fastq.gz
Trimming mode: paired-end
Trim Galore version: 0.6.4_dev
Cutadapt version: 4.8
Python version: could not detect
Number of cores used for trimming: 2
Quality Phred score cutoff: 20
Quality encoding type selected: ASCII+33
Adapter sequence: 'AGATCGGAAGAGC' (Illumina TruSeq, Sanger iPCR; default (inconclusive auto-detection))
Maximum trimming error rate: 0.1 (default)
Minimum required adapter overlap (stringency): 1 bp
Minimum required sequence length for both reads before a sequence pair gets removed: 20 bp
Running FastQC on the data once trimming has completed
Output file(s) will be GZIP compressed

Cutadapt seems to be fairly up-to-date (version 4.8). Setting -j 2
Writing final adapter and quality trimmed output to benchmark-bad10_R1_trimmed.fq.gz


  >>> Now performing quality (cutoff '-q 20') and adapter trimming in a single pass for the adapter sequence: 'AGATCGGAAGAGC' from file benchmark-bad10/host_removal/benchmark-bad10_R1.fastq.gz <<< 
This is cutadapt 4.8 with Python 3.12.3
Command line parameters: -j 2 -e 0.1 -q 20 -O 1 -a AGATCGGAAGAGC benchmark-bad10/host_removal/benchmark-bad10_R1.fastq.gz
Processing single-end reads on 2 cores ...
Finished in 0.046 s (31.186 µs/read; 1.92 M reads/minute).

=== Summary ===

Total reads processed:                   1,481
Reads with adapters:                       335 (22.6%)
Reads written (passing filters):         1,481 (100.0%)

Total basepairs processed:        60,151 bp
Quality-trimmed:                   8,834 bp (14.7%)
Total written (filtered):         50,785 bp (84.4%)

=== Adapter 1 ===

Sequence: AGATCGGAAGAGC; Type: regular 3'; Length: 13; Trimmed: 335 times

Minimum overlap: 1
No. of allowed errors:
1-9 bp: 0; 10-13 bp: 1

Bases preceding removed adapters:
  A: 36.4%
  C: 29.9%
  G: 7.8%
  T: 26.0%
  none/other: 0.0%

Overview of removed sequences
length	count	expect	max.err	error counts
1	208	370.2	0	208
2	93	92.6	0	93
3	17	23.1	0	17
4	8	5.8	0	8
5	7	1.4	0	7
10	2	0.0	1	0 2

RUN STATISTICS FOR INPUT FILE: benchmark-bad10/host_removal/benchmark-bad10_R1.fastq.gz
=============================================
1481 sequences processed in total
The length threshold of paired-end sequences gets evaluated later on (in the validation step)

Writing report to '/workspace/lab/mcarthurlab/nasirja/covid-19-signal/benchmark_output/sars-cov-2-failedQC_results_dir/benchmark-bad10/adapter_trimmed/benchmark-bad10_R2.fastq.gz_trimming_report.txt'

SUMMARISING RUN PARAMETERS
==========================
Input filename: benchmark-bad10/host_removal/benchmark-bad10_R2.fastq.gz
Trimming mode: paired-end
Trim Galore version: 0.6.4_dev
Cutadapt version: 4.8
Python version: could not detect
Number of cores used for trimming: 2
Quality Phred score cutoff: 20
Quality encoding type selected: ASCII+33
Adapter sequence: 'AGATCGGAAGAGC' (Illumina TruSeq, Sanger iPCR; default (inconclusive auto-detection))
Maximum trimming error rate: 0.1 (default)
Minimum required adapter overlap (stringency): 1 bp
Minimum required sequence length for both reads before a sequence pair gets removed: 20 bp
Running FastQC on the data once trimming has completed
Output file(s) will be GZIP compressed

Cutadapt seems to be fairly up-to-date (version 4.8). Setting -j -j 2
Writing final adapter and quality trimmed output to benchmark-bad10_R2_trimmed.fq.gz


  >>> Now performing quality (cutoff '-q 20') and adapter trimming in a single pass for the adapter sequence: 'AGATCGGAAGAGC' from file benchmark-bad10/host_removal/benchmark-bad10_R2.fastq.gz <<< 
This is cutadapt 4.8 with Python 3.12.3
Command line parameters: -j 2 -e 0.1 -q 20 -O 1 -a AGATCGGAAGAGC benchmark-bad10/host_removal/benchmark-bad10_R2.fastq.gz
Processing single-end reads on 2 cores ...
Finished in 0.047 s (31.704 µs/read; 1.89 M reads/minute).

=== Summary ===

Total reads processed:                   1,481
Reads with adapters:                       307 (20.7%)
Reads written (passing filters):         1,481 (100.0%)

Total basepairs processed:        60,784 bp
Quality-trimmed:                  10,231 bp (16.8%)
Total written (filtered):         50,099 bp (82.4%)

=== Adapter 1 ===

Sequence: AGATCGGAAGAGC; Type: regular 3'; Length: 13; Trimmed: 307 times

Minimum overlap: 1
No. of allowed errors:
1-9 bp: 0; 10-13 bp: 1

Bases preceding removed adapters:
  A: 37.1%
  C: 22.1%
  G: 6.5%
  T: 33.9%
  none/other: 0.3%

Overview of removed sequences
length	count	expect	max.err	error counts
1	193	370.2	0	193
2	96	92.6	0	96
3	9	23.1	0	9
4	4	5.8	0	4
5	4	1.4	0	4
6	1	0.4	0	1

RUN STATISTICS FOR INPUT FILE: benchmark-bad10/host_removal/benchmark-bad10_R2.fastq.gz
=============================================
1481 sequences processed in total
The length threshold of paired-end sequences gets evaluated later on (in the validation step)

Validate paired-end files benchmark-bad10_R1_trimmed.fq.gz and benchmark-bad10_R2_trimmed.fq.gz
file_1: benchmark-bad10_R1_trimmed.fq.gz, file_2: benchmark-bad10_R2_trimmed.fq.gz


>>>>> Now validing the length of the 2 paired-end infiles: benchmark-bad10_R1_trimmed.fq.gz and benchmark-bad10_R2_trimmed.fq.gz <<<<<
Writing validated paired-end Read 1 reads to benchmark-bad10_R1_val_1.fq.gz
Writing validated paired-end Read 2 reads to benchmark-bad10_R2_val_2.fq.gz

Total number of sequences analysed: 1481

Number of sequence pairs removed because at least one read was shorter than the length cutoff (20 bp): 50 (3.38%)


  >>> Now running FastQC on the validated data benchmark-bad10_R1_val_1.fq.gz<<<

Started analysis of benchmark-bad10_R1_val_1.fq.gz
Approx 75% complete for benchmark-bad10_R1_val_1.fq.gz

  >>> Now running FastQC on the validated data benchmark-bad10_R2_val_2.fq.gz<<<

Started analysis of benchmark-bad10_R2_val_2.fq.gz
Approx 75% complete for benchmark-bad10_R2_val_2.fq.gz
Deleting both intermediate output files benchmark-bad10_R1_trimmed.fq.gz and benchmark-bad10_R2_trimmed.fq.gz

====================================================================================================

