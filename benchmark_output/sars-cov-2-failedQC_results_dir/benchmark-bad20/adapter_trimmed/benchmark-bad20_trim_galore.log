Path to Cutadapt set as: 'cutadapt' (default)
Cutadapt seems to be working fine (tested command 'cutadapt --version')
Cutadapt version: 4.8
Could not detect version of Python used by Cutadapt from the first line of Cutadapt (but found this: >>>#!/bin/sh<<<)
Letting the (modified) Cutadapt deal with the Python version instead
Parallel gzip (pigz) detected. Proceeding with multicore (de)compression using 2 cores

No quality encoding type selected. Assuming that the data provided uses Sanger encoded Phred scores (default)

Output will be written into the directory: /workspace/lab/mcarthurlab/nasirja/covid-19-signal/benchmark_output/sars-cov-2-failedQC_results_dir/benchmark-bad20/adapter_trimmed/


AUTO-DETECTING ADAPTER TYPE
===========================
Attempting to auto-detect adapter type from the first 1 million sequences of the first file (>> benchmark-bad20/host_removal/benchmark-bad20_R1.fastq.gz <<)

Found perfect matches for the following adapter sequences:
Adapter type	Count	Sequence	Sequences analysed	Percentage
Nextera	44	CTGTCTCTTATA	278257	0.02
Illumina	0	AGATCGGAAGAGC	278257	0.00
smallRNA	0	TGGAATTCTCGG	278257	0.00
Using Nextera adapter for trimming (count: 44). Second best hit was Illumina (count: 0)

Writing report to '/workspace/lab/mcarthurlab/nasirja/covid-19-signal/benchmark_output/sars-cov-2-failedQC_results_dir/benchmark-bad20/adapter_trimmed/benchmark-bad20_R1.fastq.gz_trimming_report.txt'

SUMMARISING RUN PARAMETERS
==========================
Input filename: benchmark-bad20/host_removal/benchmark-bad20_R1.fastq.gz
Trimming mode: paired-end
Trim Galore version: 0.6.4_dev
Cutadapt version: 4.8
Python version: could not detect
Number of cores used for trimming: 2
Quality Phred score cutoff: 20
Quality encoding type selected: ASCII+33
Adapter sequence: 'CTGTCTCTTATA' (Nextera Transposase sequence; auto-detected)
Maximum trimming error rate: 0.1 (default)
Minimum required adapter overlap (stringency): 1 bp
Minimum required sequence length for both reads before a sequence pair gets removed: 20 bp
Running FastQC on the data once trimming has completed
Output file(s) will be GZIP compressed

Cutadapt seems to be fairly up-to-date (version 4.8). Setting -j 2
Writing final adapter and quality trimmed output to benchmark-bad20_R1_trimmed.fq.gz


  >>> Now performing quality (cutoff '-q 20') and adapter trimming in a single pass for the adapter sequence: 'CTGTCTCTTATA' from file benchmark-bad20/host_removal/benchmark-bad20_R1.fastq.gz <<< 
This is cutadapt 4.8 with Python 3.12.3
Command line parameters: -j 2 -e 0.1 -q 20 -O 1 -a CTGTCTCTTATA benchmark-bad20/host_removal/benchmark-bad20_R1.fastq.gz
Processing single-end reads on 2 cores ...
Finished in 5.738 s (20.623 µs/read; 2.91 M reads/minute).

=== Summary ===

Total reads processed:                 278,257
Reads with adapters:                    38,481 (13.8%)
Reads written (passing filters):       278,257 (100.0%)

Total basepairs processed:    40,004,222 bp
Quality-trimmed:                 370,976 bp (0.9%)
Total written (filtered):     39,579,044 bp (98.9%)

=== Adapter 1 ===

Sequence: CTGTCTCTTATA; Type: regular 3'; Length: 12; Trimmed: 38481 times

Minimum overlap: 1
No. of allowed errors:
1-9 bp: 0; 10-12 bp: 1

Bases preceding removed adapters:
  A: 42.9%
  C: 15.1%
  G: 18.1%
  T: 23.9%
  none/other: 0.0%

Overview of removed sequences
length	count	expect	max.err	error counts
1	31362	69564.2	0	31362
2	4772	17391.1	0	4772
3	1672	4347.8	0	1672
4	159	1086.9	0	159
5	405	271.7	0	405
6	6	67.9	0	6
8	2	4.2	0	2
11	2	0.1	1	0 2
12	1	0.0	1	0 1
16	3	0.0	1	1 2
18	3	0.0	1	1 2
19	1	0.0	1	1
20	2	0.0	1	1 1
23	3	0.0	1	0 3
24	2	0.0	1	0 2
26	5	0.0	1	2 3
27	2	0.0	1	2
28	1	0.0	1	0 1
29	1	0.0	1	1
31	1	0.0	1	0 1
32	1	0.0	1	1
36	2	0.0	1	1 1
37	3	0.0	1	2 1
38	2	0.0	1	1 1
39	1	0.0	1	1
41	1	0.0	1	0 1
42	1	0.0	1	1
44	3	0.0	1	1 2
46	1	0.0	1	0 1
47	1	0.0	1	0 1
52	2	0.0	1	1 1
55	2	0.0	1	1 1
56	4	0.0	1	2 2
58	6	0.0	1	2 4
59	1	0.0	1	1
60	2	0.0	1	0 2
61	2	0.0	1	1 1
62	2	0.0	1	1 1
63	3	0.0	1	2 1
64	1	0.0	1	1
65	1	0.0	1	0 1
66	1	0.0	1	0 1
67	1	0.0	1	1
68	1	0.0	1	1
71	1	0.0	1	0 1
72	3	0.0	1	1 2
73	3	0.0	1	0 3
74	1	0.0	1	1
75	4	0.0	1	3 1
76	2	0.0	1	1 1
77	1	0.0	1	1
78	1	0.0	1	0 1
79	1	0.0	1	1
80	2	0.0	1	1 1
83	2	0.0	1	0 2
85	1	0.0	1	0 1
87	1	0.0	1	0 1
90	1	0.0	1	0 1
99	1	0.0	1	0 1
101	1	0.0	1	1
106	1	0.0	1	1
109	1	0.0	1	0 1
113	1	0.0	1	1
116	1	0.0	1	0 1
117	1	0.0	1	0 1

RUN STATISTICS FOR INPUT FILE: benchmark-bad20/host_removal/benchmark-bad20_R1.fastq.gz
=============================================
278257 sequences processed in total
The length threshold of paired-end sequences gets evaluated later on (in the validation step)

Writing report to '/workspace/lab/mcarthurlab/nasirja/covid-19-signal/benchmark_output/sars-cov-2-failedQC_results_dir/benchmark-bad20/adapter_trimmed/benchmark-bad20_R2.fastq.gz_trimming_report.txt'

SUMMARISING RUN PARAMETERS
==========================
Input filename: benchmark-bad20/host_removal/benchmark-bad20_R2.fastq.gz
Trimming mode: paired-end
Trim Galore version: 0.6.4_dev
Cutadapt version: 4.8
Python version: could not detect
Number of cores used for trimming: 2
Quality Phred score cutoff: 20
Quality encoding type selected: ASCII+33
Adapter sequence: 'CTGTCTCTTATA' (Nextera Transposase sequence; auto-detected)
Maximum trimming error rate: 0.1 (default)
Minimum required adapter overlap (stringency): 1 bp
Minimum required sequence length for both reads before a sequence pair gets removed: 20 bp
Running FastQC on the data once trimming has completed
Output file(s) will be GZIP compressed

Cutadapt seems to be fairly up-to-date (version 4.8). Setting -j -j 2
Writing final adapter and quality trimmed output to benchmark-bad20_R2_trimmed.fq.gz


  >>> Now performing quality (cutoff '-q 20') and adapter trimming in a single pass for the adapter sequence: 'CTGTCTCTTATA' from file benchmark-bad20/host_removal/benchmark-bad20_R2.fastq.gz <<< 
This is cutadapt 4.8 with Python 3.12.3
Command line parameters: -j 2 -e 0.1 -q 20 -O 1 -a CTGTCTCTTATA benchmark-bad20/host_removal/benchmark-bad20_R2.fastq.gz
Processing single-end reads on 2 cores ...
Finished in 6.108 s (21.952 µs/read; 2.73 M reads/minute).

=== Summary ===

Total reads processed:                 278,257
Reads with adapters:                    38,299 (13.8%)
Reads written (passing filters):       278,257 (100.0%)

Total basepairs processed:    40,045,166 bp
Quality-trimmed:                 404,206 bp (1.0%)
Total written (filtered):     39,572,912 bp (98.8%)

=== Adapter 1 ===

Sequence: CTGTCTCTTATA; Type: regular 3'; Length: 12; Trimmed: 38299 times

Minimum overlap: 1
No. of allowed errors:
1-9 bp: 0; 10-12 bp: 1

Bases preceding removed adapters:
  A: 41.9%
  C: 15.3%
  G: 18.4%
  T: 24.5%
  none/other: 0.0%

Overview of removed sequences
length	count	expect	max.err	error counts
1	30743	69564.2	0	30743
2	4880	17391.1	0	4880
3	1720	4347.8	0	1720
4	249	1086.9	0	249
5	371	271.7	0	371
6	6	67.9	0	6
7	1	17.0	0	1
8	1	4.2	0	1
9	1	1.1	0	1
10	4	0.3	1	1 3
11	2	0.1	1	0 2
12	3	0.0	1	0 3
13	4	0.0	1	2 2
14	1	0.0	1	0 1
15	3	0.0	1	0 3
16	4	0.0	1	1 3
17	8	0.0	1	2 6
18	2	0.0	1	1 1
19	2	0.0	1	0 2
20	3	0.0	1	0 3
21	4	0.0	1	0 4
22	10	0.0	1	3 7
23	7	0.0	1	0 7
24	1	0.0	1	0 1
25	2	0.0	1	0 2
26	1	0.0	1	0 1
27	3	0.0	1	0 3
28	8	0.0	1	4 4
29	6	0.0	1	2 4
30	2	0.0	1	0 2
31	1	0.0	1	0 1
32	5	0.0	1	1 4
33	4	0.0	1	1 3
34	6	0.0	1	2 4
35	3	0.0	1	1 2
36	3	0.0	1	1 2
37	2	0.0	1	1 1
38	4	0.0	1	1 3
39	8	0.0	1	0 8
40	5	0.0	1	2 3
41	4	0.0	1	2 2
42	8	0.0	1	2 6
43	3	0.0	1	1 2
44	2	0.0	1	0 2
45	1	0.0	1	0 1
46	2	0.0	1	1 1
47	4	0.0	1	1 3
49	2	0.0	1	1 1
50	1	0.0	1	0 1
51	2	0.0	1	1 1
52	3	0.0	1	0 3
53	2	0.0	1	1 1
54	3	0.0	1	1 2
55	4	0.0	1	1 3
56	2	0.0	1	0 2
58	2	0.0	1	0 2
59	1	0.0	1	0 1
60	3	0.0	1	0 3
61	3	0.0	1	2 1
62	1	0.0	1	0 1
63	2	0.0	1	0 2
64	3	0.0	1	1 2
66	9	0.0	1	4 5
67	2	0.0	1	1 1
68	2	0.0	1	1 1
69	2	0.0	1	0 2
70	1	0.0	1	0 1
71	1	0.0	1	0 1
72	3	0.0	1	0 3
73	3	0.0	1	1 2
74	4	0.0	1	1 3
75	6	0.0	1	0 6
76	4	0.0	1	0 4
77	5	0.0	1	0 5
78	5	0.0	1	0 5
79	4	0.0	1	3 1
80	2	0.0	1	0 2
81	4	0.0	1	0 4
82	3	0.0	1	3
83	1	0.0	1	0 1
84	2	0.0	1	0 2
85	4	0.0	1	0 4
86	3	0.0	1	1 2
88	2	0.0	1	1 1
89	4	0.0	1	0 4
90	6	0.0	1	1 5
91	4	0.0	1	0 4
94	4	0.0	1	0 4
95	5	0.0	1	1 4
96	4	0.0	1	2 2
97	2	0.0	1	1 1
98	1	0.0	1	0 1
99	1	0.0	1	0 1
100	1	0.0	1	0 1
101	1	0.0	1	0 1
103	6	0.0	1	2 4
104	2	0.0	1	1 1
105	2	0.0	1	0 2
106	5	0.0	1	1 4
107	2	0.0	1	0 2
108	2	0.0	1	0 2
109	1	0.0	1	0 1
110	1	0.0	1	0 1
111	1	0.0	1	0 1
112	2	0.0	1	0 2
113	1	0.0	1	0 1
114	1	0.0	1	1
115	3	0.0	1	0 3
116	4	0.0	1	1 3
117	1	0.0	1	0 1
118	2	0.0	1	0 2
120	1	0.0	1	0 1
121	2	0.0	1	1 1
123	1	0.0	1	1
126	1	0.0	1	0 1
135	1	0.0	1	0 1
137	1	0.0	1	0 1

RUN STATISTICS FOR INPUT FILE: benchmark-bad20/host_removal/benchmark-bad20_R2.fastq.gz
=============================================
278257 sequences processed in total
The length threshold of paired-end sequences gets evaluated later on (in the validation step)

Validate paired-end files benchmark-bad20_R1_trimmed.fq.gz and benchmark-bad20_R2_trimmed.fq.gz
file_1: benchmark-bad20_R1_trimmed.fq.gz, file_2: benchmark-bad20_R2_trimmed.fq.gz


>>>>> Now validing the length of the 2 paired-end infiles: benchmark-bad20_R1_trimmed.fq.gz and benchmark-bad20_R2_trimmed.fq.gz <<<<<
Writing validated paired-end Read 1 reads to benchmark-bad20_R1_val_1.fq.gz
Writing validated paired-end Read 2 reads to benchmark-bad20_R2_val_2.fq.gz

Total number of sequences analysed: 278257

Number of sequence pairs removed because at least one read was shorter than the length cutoff (20 bp): 2813 (1.01%)


  >>> Now running FastQC on the validated data benchmark-bad20_R1_val_1.fq.gz<<<

Started analysis of benchmark-bad20_R1_val_1.fq.gz
Approx 5% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 10% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 15% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 20% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 25% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 30% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 35% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 40% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 45% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 50% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 55% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 60% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 65% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 70% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 75% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 80% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 85% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 90% complete for benchmark-bad20_R1_val_1.fq.gz
Approx 95% complete for benchmark-bad20_R1_val_1.fq.gz

  >>> Now running FastQC on the validated data benchmark-bad20_R2_val_2.fq.gz<<<

Started analysis of benchmark-bad20_R2_val_2.fq.gz
Approx 5% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 10% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 15% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 20% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 25% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 30% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 35% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 40% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 45% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 50% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 55% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 60% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 65% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 70% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 75% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 80% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 85% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 90% complete for benchmark-bad20_R2_val_2.fq.gz
Approx 95% complete for benchmark-bad20_R2_val_2.fq.gz
Deleting both intermediate output files benchmark-bad20_R1_trimmed.fq.gz and benchmark-bad20_R2_trimmed.fq.gz

====================================================================================================

