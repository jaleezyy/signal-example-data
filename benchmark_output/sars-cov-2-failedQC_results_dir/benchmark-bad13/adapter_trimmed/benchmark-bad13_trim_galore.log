Path to Cutadapt set as: 'cutadapt' (default)
Cutadapt seems to be working fine (tested command 'cutadapt --version')
Cutadapt version: 4.8
Could not detect version of Python used by Cutadapt from the first line of Cutadapt (but found this: >>>#!/bin/sh<<<)
Letting the (modified) Cutadapt deal with the Python version instead
Parallel gzip (pigz) detected. Proceeding with multicore (de)compression using 2 cores

No quality encoding type selected. Assuming that the data provided uses Sanger encoded Phred scores (default)

Output will be written into the directory: /workspace/lab/mcarthurlab/nasirja/covid-19-signal/benchmark_output/sars-cov-2-failedQC_results_dir/benchmark-bad13/adapter_trimmed/


AUTO-DETECTING ADAPTER TYPE
===========================
Attempting to auto-detect adapter type from the first 1 million sequences of the first file (>> benchmark-bad13/host_removal/benchmark-bad13_R1.fastq.gz <<)

Found perfect matches for the following adapter sequences:
Adapter type	Count	Sequence	Sequences analysed	Percentage
Nextera	28	CTGTCTCTTATA	355210	0.01
smallRNA	0	TGGAATTCTCGG	355210	0.00
Illumina	0	AGATCGGAAGAGC	355210	0.00
Using Nextera adapter for trimming (count: 28). Second best hit was smallRNA (count: 0)

Writing report to '/workspace/lab/mcarthurlab/nasirja/covid-19-signal/benchmark_output/sars-cov-2-failedQC_results_dir/benchmark-bad13/adapter_trimmed/benchmark-bad13_R1.fastq.gz_trimming_report.txt'

SUMMARISING RUN PARAMETERS
==========================
Input filename: benchmark-bad13/host_removal/benchmark-bad13_R1.fastq.gz
Trimming mode: paired-end
Trim Galore version: 0.6.4_dev
Cutadapt version: 4.8
Python version: could not detect
Number of cores used for trimming: 2
Quality Phred score cutoff: 20
Quality encoding type selected: ASCII+33
Adapter sequence: 'CTGTCTCTTATA' (Nextera Transposase sequence; auto-detected)
Maximum trimming error rate: 0.1 (default)
Minimum required adapter overlap (stringency): 1 bp
Minimum required sequence length for both reads before a sequence pair gets removed: 20 bp
Running FastQC on the data once trimming has completed
Output file(s) will be GZIP compressed

Cutadapt seems to be fairly up-to-date (version 4.8). Setting -j 2
Writing final adapter and quality trimmed output to benchmark-bad13_R1_trimmed.fq.gz


  >>> Now performing quality (cutoff '-q 20') and adapter trimming in a single pass for the adapter sequence: 'CTGTCTCTTATA' from file benchmark-bad13/host_removal/benchmark-bad13_R1.fastq.gz <<< 
This is cutadapt 4.8 with Python 3.12.3
Command line parameters: -j 2 -e 0.1 -q 20 -O 1 -a CTGTCTCTTATA benchmark-bad13/host_removal/benchmark-bad13_R1.fastq.gz
Processing single-end reads on 2 cores ...
Finished in 5.433 s (15.296 µs/read; 3.92 M reads/minute).

=== Summary ===

Total reads processed:                 355,210
Reads with adapters:                   106,077 (29.9%)
Reads written (passing filters):       355,210 (100.0%)

Total basepairs processed:    41,697,273 bp
Quality-trimmed:                  35,773 bp (0.1%)
Total written (filtered):     41,524,152 bp (99.6%)

=== Adapter 1 ===

Sequence: CTGTCTCTTATA; Type: regular 3'; Length: 12; Trimmed: 106077 times

Minimum overlap: 1
No. of allowed errors:
1-9 bp: 0; 10-12 bp: 1

Bases preceding removed adapters:
  A: 46.4%
  C: 17.3%
  G: 18.3%
  T: 18.1%
  none/other: 0.0%

Overview of removed sequences
length	count	expect	max.err	error counts
1	90655	88802.5	0	90655
2	10958	22200.6	0	10958
3	3036	5550.2	0	3036
4	948	1387.5	0	948
5	125	346.9	0	125
6	187	86.7	0	187
7	8	21.7	0	8
8	4	5.4	0	4
9	1	1.4	0	0 1
10	2	0.3	1	1 1
12	2	0.0	1	1 1
13	4	0.0	1	1 3
14	1	0.0	1	1
15	4	0.0	1	2 2
16	2	0.0	1	0 2
17	1	0.0	1	0 1
18	3	0.0	1	1 2
20	1	0.0	1	1
22	1	0.0	1	1
24	1	0.0	1	1
25	1	0.0	1	0 1
26	1	0.0	1	0 1
28	2	0.0	1	0 2
30	1	0.0	1	0 1
31	1	0.0	1	1
32	2	0.0	1	0 2
33	3	0.0	1	0 3
35	1	0.0	1	0 1
37	1	0.0	1	0 1
38	2	0.0	1	1 1
39	1	0.0	1	0 1
40	2	0.0	1	0 2
41	4	0.0	1	1 3
42	1	0.0	1	0 1
43	1	0.0	1	1
44	1	0.0	1	0 1
46	3	0.0	1	0 3
49	2	0.0	1	0 2
50	1	0.0	1	0 1
52	2	0.0	1	0 2
53	1	0.0	1	1
54	5	0.0	1	1 4
56	2	0.0	1	0 2
57	2	0.0	1	0 2
58	3	0.0	1	0 3
59	1	0.0	1	0 1
60	3	0.0	1	1 2
61	2	0.0	1	0 2
62	1	0.0	1	0 1
63	1	0.0	1	1
64	4	0.0	1	1 3
65	2	0.0	1	0 2
68	2	0.0	1	0 2
70	2	0.0	1	0 2
71	1	0.0	1	0 1
72	1	0.0	1	0 1
73	1	0.0	1	0 1
74	1	0.0	1	0 1
75	1	0.0	1	0 1
76	2	0.0	1	0 2
78	2	0.0	1	0 2
79	4	0.0	1	2 2
80	1	0.0	1	0 1
81	1	0.0	1	0 1
82	3	0.0	1	0 3
83	2	0.0	1	0 2
86	1	0.0	1	0 1
87	2	0.0	1	1 1
88	1	0.0	1	1
89	3	0.0	1	0 3
90	1	0.0	1	0 1
91	2	0.0	1	0 2
92	1	0.0	1	0 1
93	3	0.0	1	0 3
94	4	0.0	1	2 2
95	1	0.0	1	0 1
96	1	0.0	1	0 1
98	2	0.0	1	0 2
99	2	0.0	1	1 1
101	2	0.0	1	1 1
104	1	0.0	1	0 1
105	1	0.0	1	0 1
106	2	0.0	1	0 2
107	2	0.0	1	1 1
108	3	0.0	1	0 3
109	2	0.0	1	0 2
110	1	0.0	1	0 1
111	2	0.0	1	0 2
112	1	0.0	1	0 1
113	1	0.0	1	0 1
114	2	0.0	1	0 2
116	2	0.0	1	0 2
119	1	0.0	1	0 1
123	2	0.0	1	0 2

RUN STATISTICS FOR INPUT FILE: benchmark-bad13/host_removal/benchmark-bad13_R1.fastq.gz
=============================================
355210 sequences processed in total
The length threshold of paired-end sequences gets evaluated later on (in the validation step)

Writing report to '/workspace/lab/mcarthurlab/nasirja/covid-19-signal/benchmark_output/sars-cov-2-failedQC_results_dir/benchmark-bad13/adapter_trimmed/benchmark-bad13_R2.fastq.gz_trimming_report.txt'

SUMMARISING RUN PARAMETERS
==========================
Input filename: benchmark-bad13/host_removal/benchmark-bad13_R2.fastq.gz
Trimming mode: paired-end
Trim Galore version: 0.6.4_dev
Cutadapt version: 4.8
Python version: could not detect
Number of cores used for trimming: 2
Quality Phred score cutoff: 20
Quality encoding type selected: ASCII+33
Adapter sequence: 'CTGTCTCTTATA' (Nextera Transposase sequence; auto-detected)
Maximum trimming error rate: 0.1 (default)
Minimum required adapter overlap (stringency): 1 bp
Minimum required sequence length for both reads before a sequence pair gets removed: 20 bp
Running FastQC on the data once trimming has completed
Output file(s) will be GZIP compressed

Cutadapt seems to be fairly up-to-date (version 4.8). Setting -j -j 2
Writing final adapter and quality trimmed output to benchmark-bad13_R2_trimmed.fq.gz


  >>> Now performing quality (cutoff '-q 20') and adapter trimming in a single pass for the adapter sequence: 'CTGTCTCTTATA' from file benchmark-bad13/host_removal/benchmark-bad13_R2.fastq.gz <<< 
This is cutadapt 4.8 with Python 3.12.3
Command line parameters: -j 2 -e 0.1 -q 20 -O 1 -a CTGTCTCTTATA benchmark-bad13/host_removal/benchmark-bad13_R2.fastq.gz
Processing single-end reads on 2 cores ...
Finished in 5.840 s (16.441 µs/read; 3.65 M reads/minute).

=== Summary ===

Total reads processed:                 355,210
Reads with adapters:                   105,078 (29.6%)
Reads written (passing filters):       355,210 (100.0%)

Total basepairs processed:    41,769,379 bp
Quality-trimmed:                  89,931 bp (0.2%)
Total written (filtered):     41,523,262 bp (99.4%)

=== Adapter 1 ===

Sequence: CTGTCTCTTATA; Type: regular 3'; Length: 12; Trimmed: 105078 times

Minimum overlap: 1
No. of allowed errors:
1-9 bp: 0; 10-12 bp: 1

Bases preceding removed adapters:
  A: 45.9%
  C: 17.3%
  G: 18.5%
  T: 18.3%
  none/other: 0.0%

Overview of removed sequences
length	count	expect	max.err	error counts
1	89121	88802.5	0	89121
2	11021	22200.6	0	11021
3	3083	5550.2	0	3083
4	1054	1387.5	0	1054
5	106	346.9	0	106
6	182	86.7	0	182
7	8	21.7	0	8
8	3	5.4	0	3
9	7	1.4	0	6 1
10	2	0.3	1	0 2
11	20	0.1	1	6 14
12	3	0.0	1	0 3
13	2	0.0	1	0 2
14	4	0.0	1	0 4
15	4	0.0	1	1 3
16	1	0.0	1	1
17	12	0.0	1	0 12
19	8	0.0	1	0 8
20	1	0.0	1	0 1
21	6	0.0	1	1 5
22	5	0.0	1	1 4
23	4	0.0	1	0 4
24	2	0.0	1	0 2
25	5	0.0	1	0 5
26	8	0.0	1	0 8
27	2	0.0	1	1 1
28	4	0.0	1	1 3
29	7	0.0	1	0 7
30	8	0.0	1	1 7
31	1	0.0	1	0 1
32	3	0.0	1	0 3
33	6	0.0	1	0 6
34	7	0.0	1	0 7
35	8	0.0	1	0 8
36	3	0.0	1	0 3
37	13	0.0	1	2 11
38	12	0.0	1	1 11
39	8	0.0	1	0 8
40	4	0.0	1	1 3
41	4	0.0	1	0 4
42	5	0.0	1	2 3
43	4	0.0	1	0 4
44	5	0.0	1	0 5
45	4	0.0	1	1 3
46	8	0.0	1	3 5
47	13	0.0	1	3 10
48	5	0.0	1	0 5
49	4	0.0	1	2 2
50	1	0.0	1	0 1
51	5	0.0	1	1 4
52	5	0.0	1	0 5
53	7	0.0	1	1 6
54	7	0.0	1	0 7
55	5	0.0	1	1 4
56	3	0.0	1	0 3
57	8	0.0	1	2 6
58	1	0.0	1	1
59	7	0.0	1	2 5
60	3	0.0	1	0 3
61	5	0.0	1	2 3
62	3	0.0	1	0 3
63	4	0.0	1	0 4
64	3	0.0	1	0 3
65	3	0.0	1	2 1
66	2	0.0	1	0 2
68	4	0.0	1	0 4
69	1	0.0	1	0 1
70	6	0.0	1	2 4
71	1	0.0	1	0 1
73	4	0.0	1	0 4
74	5	0.0	1	2 3
75	5	0.0	1	0 5
76	1	0.0	1	0 1
77	6	0.0	1	0 6
78	5	0.0	1	1 4
79	2	0.0	1	0 2
80	2	0.0	1	1 1
81	5	0.0	1	2 3
82	7	0.0	1	1 6
83	7	0.0	1	1 6
85	3	0.0	1	0 3
86	4	0.0	1	2 2
87	1	0.0	1	0 1
88	5	0.0	1	0 5
90	5	0.0	1	1 4
91	1	0.0	1	0 1
93	3	0.0	1	1 2
94	8	0.0	1	1 7
95	5	0.0	1	1 4
96	6	0.0	1	2 4
97	1	0.0	1	0 1
98	3	0.0	1	1 2
99	2	0.0	1	0 2
100	4	0.0	1	0 4
101	5	0.0	1	2 3
102	3	0.0	1	1 2
103	1	0.0	1	1
104	3	0.0	1	0 3
105	5	0.0	1	2 3
106	6	0.0	1	1 5
107	10	0.0	1	1 9
108	1	0.0	1	0 1
109	1	0.0	1	1
110	4	0.0	1	1 3
111	4	0.0	1	0 4
112	1	0.0	1	0 1
113	3	0.0	1	0 3
114	2	0.0	1	1 1
115	5	0.0	1	3 2
116	5	0.0	1	1 4
117	6	0.0	1	0 6
118	4	0.0	1	1 3
119	3	0.0	1	1 2
120	2	0.0	1	1 1
121	3	0.0	1	0 3
122	3	0.0	1	1 2
123	1	0.0	1	0 1
124	1	0.0	1	0 1
125	1	0.0	1	0 1
141	1	0.0	1	0 1

RUN STATISTICS FOR INPUT FILE: benchmark-bad13/host_removal/benchmark-bad13_R2.fastq.gz
=============================================
355210 sequences processed in total
The length threshold of paired-end sequences gets evaluated later on (in the validation step)

Validate paired-end files benchmark-bad13_R1_trimmed.fq.gz and benchmark-bad13_R2_trimmed.fq.gz
file_1: benchmark-bad13_R1_trimmed.fq.gz, file_2: benchmark-bad13_R2_trimmed.fq.gz


>>>>> Now validing the length of the 2 paired-end infiles: benchmark-bad13_R1_trimmed.fq.gz and benchmark-bad13_R2_trimmed.fq.gz <<<<<
Writing validated paired-end Read 1 reads to benchmark-bad13_R1_val_1.fq.gz
Writing validated paired-end Read 2 reads to benchmark-bad13_R2_val_2.fq.gz

Total number of sequences analysed: 355210

Number of sequence pairs removed because at least one read was shorter than the length cutoff (20 bp): 161 (0.05%)


  >>> Now running FastQC on the validated data benchmark-bad13_R1_val_1.fq.gz<<<

Started analysis of benchmark-bad13_R1_val_1.fq.gz
Approx 5% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 10% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 15% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 20% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 25% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 30% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 35% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 40% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 45% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 50% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 55% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 60% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 65% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 70% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 75% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 80% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 85% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 90% complete for benchmark-bad13_R1_val_1.fq.gz
Approx 95% complete for benchmark-bad13_R1_val_1.fq.gz

  >>> Now running FastQC on the validated data benchmark-bad13_R2_val_2.fq.gz<<<

Started analysis of benchmark-bad13_R2_val_2.fq.gz
Approx 5% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 10% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 15% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 20% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 25% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 30% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 35% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 40% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 45% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 50% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 55% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 60% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 65% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 70% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 75% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 80% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 85% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 90% complete for benchmark-bad13_R2_val_2.fq.gz
Approx 95% complete for benchmark-bad13_R2_val_2.fq.gz
Deleting both intermediate output files benchmark-bad13_R1_trimmed.fq.gz and benchmark-bad13_R2_trimmed.fq.gz

====================================================================================================

