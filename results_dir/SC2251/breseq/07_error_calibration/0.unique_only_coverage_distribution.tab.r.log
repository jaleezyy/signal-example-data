ARGUMENT 'distribution_file=SC2251/breseq/07_error_calibration/0.unique_only_coverage_distribution.tab' __ignored__

ARGUMENT 'plot_file=SC2251/breseq/output/calibration/0.unique_coverage.pdf' __ignored__

ARGUMENT 'deletion_propagation_pr_cutoff=0.000289143' __ignored__


R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-conda_cos6-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2017 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs()) {
+   ta = strsplit(e,"=",fixed=TRUE)
+   if(! is.na(ta[[1]][2])) {
+     temp = ta[[1]][2]
+  #   temp = as.numeric(temp) #Im only inputting numbers so I added this to recognize scientific notation
+     if(substr(ta[[1]][1],nchar(ta[[1]][1]),nchar(ta[[1]][1])) == "I") {
+       temp = as.integer(temp)
+     }
+     if(substr(ta[[1]][1],nchar(ta[[1]][1]),nchar(ta[[1]][1])) == "N") {
+       temp = as.numeric(temp)
+     }
+     assign(ta[[1]][1],temp)
+     cat("assigned ",ta[[1]][1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[[1]][1]," the value of TRUE\n")
+   }
+ }
assigned  /workspace/home/nasirja/covid-19-signal/.snakemake/conda/1f267c8dfdaa0356ebaad13adc66d00a/lib/R/bin/exec/R  the value of TRUE
assigned  --vanilla  the value of TRUE
assigned  distribution_file  the value of | SC2251/breseq/07_error_calibration/0.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | SC2251/breseq/output/calibration/0.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.000289143 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 1 to 5.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  2.235208  Size:  10000 
1   5 
2.235208   10000 
1   5 
2.235208   10000 
1   5 
2.23521   10000 
1   5 
2.235208   10000.01 
1   5 
2.208972   10000 
1   5 
2.208974   10000 
1   5 
2.208972   10000.01 
1   5 
1.956211   10000 
1   5 
1.956212   10000 
1   5 
1.956211   10000.01 
1   5 
1.999734   10000 
1   5 
1.999736   10000 
1   5 
1.999734   10000.01 
1   5 
1.994345   10000 
1   5 
1.994347   10000 
1   5 
1.994345   10000.01 
1   5 
1.99421   10000 
1   5 
1.994212   10000 
1   5 
1.99421   10000.01 
1   5 
1.994211   10000 
1   5 
1.994213   10000 
1   5 
1.994211   10000.01 
Fit Mean:  1.994211  Size:  10000  Code:  2 
Try Mean:  2.235208  Size:  1000 
1   5 
2.235208   1000 
1   5 
2.235208   1000 
1   5 
2.23521   1000 
1   5 
2.235208   1000.001 
1   5 
2.209084   1000 
1   5 
2.209086   1000 
1   5 
2.209084   1000.001 
1   5 
1.956686   1000 
1   5 
1.956687   1000 
1   5 
1.956686   1000.001 
1   5 
2.000134   1000 
1   5 
2.000136   1000 
1   5 
2.000134   1000.001 
1   5 
1.994754   1000 
1   5 
1.994756   1000 
1   5 
1.994754   1000.001 
1   5 
1.994619   1000 
1   5 
1.994621   1000 
1   5 
1.994619   1000.001 
1   5 
1.99462   1000 
1   5 
1.994622   1000 
1   5 
1.99462   1000.001 
Fit Mean:  1.99462  Size:  1000  Code:  2 
Try Mean:  2.235208  Size:  100 
1   5 
2.235208   100 
1   5 
2.235208   100 
1   5 
2.23521   100 
1   5 
2.235208   100.0001 
1   5 
2.210178   100 
1   5 
2.21018   100 
1   5 
2.210178   100.0001 
1   5 
1.961421   100 
1   5 
1.961423   100 
1   5 
1.961421   100.0001 
1   5 
2.0041   100 
1   5 
2.004102   100 
1   5 
2.0041   100.0001 
1   5 
1.998816   100.0001 
1   5 
1.998818   100.0001 
1   5 
1.998816   100.0002 
1   5 
1.998684   100.0001 
1   5 
1.998686   100.0001 
1   5 
1.998684   100.0002 
1   5 
1.998682   100.0001 
1   5 
1.998684   100.0001 
1   5 
1.998682   100.0002 
Fit Mean:  1.998682  Size:  100.0001  Code:  2 
Try Mean:  2.235208  Size:  10 
1   5 
2.235208   10 
1   5 
2.235208   10 
1   5 
2.23521   10 
1   5 
2.235208   10.00001 
1   5 
2.218877   10.0001 
1   5 
2.218879   10.0001 
1   5 
2.218877   10.00011 
1   5 
2.008177   10.00508 
1   5 
2.008179   10.00508 
1   5 
2.008177   10.00509 
1   5 
2.041911   10.00715 
1   5 
2.041913   10.00715 
1   5 
2.041911   10.00716 
1   5 
2.038044   10.00991 
1   5 
2.038046   10.00991 
1   5 
2.038044   10.00992 
1   5 
2.036194   10.01552 
1   5 
2.036196   10.01552 
1   5 
2.036194   10.01553 
1   5 
2.030841   10.0483 
1   5 
2.030843   10.0483 
1   5 
2.030841   10.04831 
1   5 
2.023704   10.1302 
1   5 
2.023706   10.1302 
1   5 
2.023704   10.13021 
1   5 
2.011845   10.36862 
1   5 
2.011847   10.36862 
1   5 
2.011845   10.36863 
1   5 
1.995958   10.94256 
1   5 
1.99596   10.94256 
1   5 
1.995958   10.94257 
1   5 
1.978773   12.21979 
1   5 
1.978775   12.21979 
1   5 
1.978773   12.2198 
1   5 
1.969716   14.73581 
1   5 
1.969718   14.73581 
1   5 
1.969716   14.73583 
1   5 
1.981082   19.12132 
1   5 
1.981084   19.12132 
1   5 
1.981082   19.12134 
1   5 
2.004107   24.85278 
1   5 
2.004109   24.85278 
1   5 
2.004107   24.85281 
1   5 
2.016791   30.94746 
1   5 
2.016793   30.94746 
1   5 
2.016791   30.94749 
1   5 
2.019237   38.91204 
1   5 
2.019239   38.91204 
1   5 
2.019237   38.91207 
1   5 
2.012214   51.31378 
1   5 
2.012216   51.31378 
1   5 
2.012214   51.31383 
1   5 
2.000664   68.07251 
1   5 
2.000666   68.07251 
1   5 
2.000664   68.07258 
1   5 
1.99287   87.41681 
1   5 
1.992872   87.41681 
1   5 
1.99287   87.41689 
1   5 
1.990034   111.9008 
1   5 
1.990036   111.9008 
1   5 
1.990034   111.9009 
1   5 
1.991428   146.7859 
1   5 
1.99143   146.7859 
1   5 
1.991428   146.7861 
1   5 
1.994787   193.2944 
1   5 
1.994789   193.2944 
1   5 
1.994787   193.2946 
1   5 
1.997154   252.1441 
1   5 
1.997156   252.1441 
1   5 
1.997154   252.1444 
1   5 
1.997637   330.0331 
1   5 
1.997639   330.0331 
1   5 
1.997637   330.0335 
1   5 
1.99654   437.0724 
1   5 
1.996542   437.0724 
1   5 
1.99654   437.0729 
1   5 
1.994907   579.0075 
1   5 
1.994909   579.0075 
1   5 
1.994907   579.0081 
1   5 
1.99376   762.1087 
1   5 
1.993762   762.1087 
1   5 
1.99376   762.1094 
1   5 
1.993427   1003.719 
1   5 
1.993429   1003.719 
1   5 
1.993427   1003.72 
1   5 
1.993741   1328.213 
1   5 
1.993743   1328.213 
1   5 
1.993741   1328.214 
1   5 
1.994266   1757.567 
1   5 
1.994268   1757.567 
1   5 
1.994266   1757.569 
1   5 
1.994615   2320.794 
1   5 
1.994617   2320.794 
1   5 
1.994615   2320.796 
1   5 
1.994657   3069.249 
1   5 
1.994659   3069.249 
1   5 
1.994657   3069.253 
1   5 
1.994468   4066.106 
1   5 
1.99447   4066.106 
1   5 
1.994468   4066.11 
1   5 
1.994224   5385.293 
1   5 
1.994226   5385.293 
1   5 
1.994224   5385.298 
1   5 
1.994067   7121.731 
1   5 
1.994069   7121.731 
1   5 
1.994067   7121.738 
1   5 
1.994039   9405.808 
1   5 
1.994041   9405.808 
1   5 
1.994039   9405.818 
1   5 
1.994103   12492.65 
1   5 
1.994105   12492.65 
1   5 
1.994103   12492.66 
1   5 
1.994186   16542.66 
1   5 
1.994188   16542.66 
1   5 
1.994186   16542.68 
1   5 
1.994235   21927.07 
1   5 
1.994237   21927.07 
1   5 
1.994235   21927.09 
1   5 
1.994236   29051.49 
1   5 
1.994238   29051.49 
1   5 
1.994236   29051.52 
1   5 
1.994204   37900.37 
1   5 
1.994206   37900.37 
1   5 
1.994204   37900.41 
1   5 
1.994174   48147.13 
1   5 
1.994176   48147.13 
1   5 
1.994174   48147.18 
Fit Mean:  1.994174  Size:  48147.13  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  1.994174  Size:  48147.13  Code:  1  Try Size:  10 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
1 5
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
48147.13   1.994174 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 48147.13
> print(nb_fit_mu);
[1] 1.994174
> 
> print(m)
[1] 3.12697
> print(v)
[1] 84.77536
> print(D)
[1] 27.11102
> 
> print(deletion_propagation_coverage)
[1] 1
> 
> warnings()
> 
