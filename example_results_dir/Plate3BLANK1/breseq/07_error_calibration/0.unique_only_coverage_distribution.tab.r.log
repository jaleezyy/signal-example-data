ARGUMENT 'distribution_file=Plate3BLANK1/breseq/07_error_calibration/0.unique_only_coverage_distribution.tab' __ignored__

ARGUMENT 'plot_file=Plate3BLANK1/breseq/output/calibration/0.unique_coverage.pdf' __ignored__

ARGUMENT 'deletion_propagation_pr_cutoff=0.000289143' __ignored__


R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-conda_cos6-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##
> ##
> ## AUTHORS
> ##
> ## Jeffrey E. Barrick <jeffrey.e.barrick@gmail.com>
> ##
> ## LICENSE AND COPYRIGHT
> ##
> ## Copyright (c) 2008-2010 Michigan State University
> ## Copyright (c) 2011-2017 The University of Texas at Austin
> ##
> ## breseq is free software; you can redistribute it and/or modify it under the
> ## terms the GNU General Public License as published by the Free Software
> ## Foundation; either version 1, or (at your option) any later version.
> ##
> ##
> 
> ## Arguments:
> ##   distribution_file=/path/to/input 
> ##   plot_file=/path/to/output 
> ##   deletion_propagation_pr_cutoff=float
> ##   plot_poisson=0 or 1
> ##   pdf_output=0 or 1
> 
> ## Returns these values printed out to output log
> ## 
> ##  1. print(nb_fit_size); # 0 if fit failed
> ##  2. print(nb_fit_mu);   # 0 if fit failed
> ##  3. print(m)q
> ##  4. print(v)
> ##  5. print(D)
> ##  6. print(deletion_propagation_coverage)
> ##     -1 if it was <1 after fitting (implying reference sequence is deleted)
> ##
> 
> plot_poisson = 0;
> pdf_output = 1;
> 
> this.print.level = 0
> #this.print.level = 2
> 
> for (e in commandArgs()) {
+   ta = strsplit(e,"=",fixed=TRUE)
+   if(! is.na(ta[[1]][2])) {
+     temp = ta[[1]][2]
+  #   temp = as.numeric(temp) #Im only inputting numbers so I added this to recognize scientific notation
+     if(substr(ta[[1]][1],nchar(ta[[1]][1]),nchar(ta[[1]][1])) == "I") {
+       temp = as.integer(temp)
+     }
+     if(substr(ta[[1]][1],nchar(ta[[1]][1]),nchar(ta[[1]][1])) == "N") {
+       temp = as.numeric(temp)
+     }
+     assign(ta[[1]][1],temp)
+     cat("assigned ",ta[[1]][1]," the value of |",temp,"|\n")
+   } else {
+     assign(ta[[1]][1],TRUE)
+     cat("assigned ",ta[[1]][1]," the value of TRUE\n")
+   }
+ }
assigned  /workspace/home/nasirja/covid-19-signal/.snakemake/conda/1f267c8dfdaa0356ebaad13adc66d00a/lib/R/bin/exec/R  the value of TRUE
assigned  --vanilla  the value of TRUE
assigned  distribution_file  the value of | Plate3BLANK1/breseq/07_error_calibration/0.unique_only_coverage_distribution.tab |
assigned  plot_file  the value of | Plate3BLANK1/breseq/output/calibration/0.unique_coverage.pdf |
assigned  deletion_propagation_pr_cutoff  the value of | 0.000289143 |
> 
> deletion_propagation_pr_cutoff = as.numeric(deletion_propagation_pr_cutoff);
> 
> ## initialize values to be filled in
> nb_fit_mu = 0
> nb_fit_size = 0
> m = 0
> v = 0
> D = 0
> deletion_propagation_coverage = -1
> 
> min_fraction_included_in_nb_fit = 0.01
> 
> #load data
> X<-read.table(distribution_file, header=T)
> 
> #table might be empty
> if (nrow(X) == 0)
+ {
+   #print out statistics
+   
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> #create the distribution vector and fit
> Y<-rep(X$coverage, X$n)
> m<-mean(Y)
> v<-var(Y)
> D<-v/m
> 
> ###
> ## Smooth the distribution with a moving average window of size 5
> ## so that we can more reliably find it's maximum value
> ###
> 
> ma5 = c(1, 1, 1, 1, 1)/5;
> 
> ## filtering fails if there are too few points
> if (nrow(X) >= 5) {
+   X$ma = filter(X$n, ma5)
+ } else {
+ 	X$ma = X$n
+ }
> 
> i<-0
> max_n <- 0;
> min_i <- max( trunc(m/4), 1 ); #prevents zero for pathological distributions
> max_i <- i;
> for (i in min_i:length(X$ma))
+ {		
+   #cat(i, "\n")
+ 	if (!is.na(X$ma[i]) && (X$ma[i] > max_n))
+ 	{
+ 		max_n = X$ma[i];
+ 		max_i = i;
+ 	}
+ }
> 
> ##
> # Censor data on the right and left of the maximum
> ##
> 
> start_i = max(floor(max_i*0.5), 1);
> end_i = min(ceiling(max_i*1.5), length(X$ma));
> 
> if (start_i == end_i)
+ {
+   print(nb_fit_size);
+   print(nb_fit_mu);
+   
+   print(m)
+   print(v)
+   print(D)
+   
+   print(deletion_propagation_coverage)
+   
+   q()
+ }
> 
> cat("Fitting from coverage of ", start_i, " to ", end_i, ".\n", sep="")
Fitting from coverage of 1 to 5.
> 
> ##
> # Coarse grain so that we are only fitting a number of bins that is 1000-2000
> #
> # The later adjustment for doing the fits this way is to multiply the means
> # of the negative binomial and poisson distributions by the binning number.
> # (The size parameter of the negative binomial doesn't need to be adjusted.)
> ##
> 
> 
> num_per_bin = trunc((end_i - start_i) / 1000)
> 
> if (num_per_bin > 1) 
+ {
+   cat("Coarse-graining for fits\n")
+   start_i_for_fits = trunc(start_i/num_per_bin)
+   end_i_for_fits = ceiling(end_i/num_per_bin)
+   num_bins = end_i - start_i  + 1
+   cat("Fitting from coverage in adjusted bins ", start_i_for_fits, " to ", end_i_for_fits, ".\n", sep="")
+   cat("Number of bins ", num_bins, ". Each bin has ", num_per_bin, " coverage values.\n", sep="")
+ 
+   # Create a new vector where we've added together values in bins
+   X.for.fits = vector("double", end_i_for_fits)
+   for (i in start_i_for_fits:end_i_for_fits)
+   {
+     for (j in 1:num_per_bin)
+     {
+       if (i*num_per_bin+j <= length(X$n))
+       {
+         X.for.fits[i] = X.for.fits[i] + X$n[i*num_per_bin+j]
+       }
+     }
+   }
+ 
+ } else {
+   ## AVOID num_per_bin equalling zero!!
+   X.for.fits = X$n[1:end_i]
+   num_per_bin = 1
+   start_i_for_fits = start_i
+   end_i_for_fits = end_i
+ }
> 
> 
> ##
> # Now perform negative binomial fitting to the censored data
> ##
> 
> inner_total<-0;
> for (i in start_i_for_fits:end_i_for_fits)
+ {
+ 	inner_total = inner_total + X.for.fits[i]; 
+ }
> # Yes: it's correct to use X here because we want the overall total total
> total_total<-sum(X$n);
> 
> ## let's preconstruct these for speed
> dist = vector("double", end_i_for_fits)
> 
> f_nb <- function(par) {
+ 
+ 	mu = par[1];
+ 	size = par[2];
+ 
+   if ((mu <= 0) || (size <= 0))
+   {
+     return(0);
+   }
+   
+   cat(start_i_for_fits, " ", end_i_for_fits, "\n");
+   cat(mu, " ", size, "\n");
+   
+ 	dist<-c()
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+ 		dist[i] <- dnbinom(i, size=size, mu=mu);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (mu, size)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> 
> ## Fit negative binomial 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> nb_fit = NULL
> ## as.numeric prevents overflow in sums involving integers
> mean_estimate = sum((as.numeric(1:end_i_for_fits)*as.numeric(X.for.fits)))/sum(as.numeric(X.for.fits))
> 
> nb_fit_mu = -1
> nb_fit_size = -1
> try_size = 100000
> try_means_index = 1
> #This is a list of different means to test <-  sometimes the actual mean doesn't lead to a fit
> try_means = c(mean_estimate, 
+               end_i_for_fits, 
+               start_i_for_fits, 
+               1*(end_i_for_fits + start_i_for_fits)/4,
+               2*(end_i_for_fits + start_i_for_fits)/4,
+               3*(end_i_for_fits + start_i_for_fits)/4
+               )
>               
>               
> nb_fit = c()
> 
> while ( ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1)) && (try_size > 0.001) && (try_means_index <= length(try_means)))
+ {
+   try_size = try_size / 10
+   try_mean = try_means[try_means_index]
+ 
+   ## SIZE ESTIMATE from the censored data can be negative, so try various values instead
+   cat("Try Mean: ", try_mean, " Size: ", try_size, "\n")
+ 
+   try( suppressWarnings(nb_fit<-nlm(f_nb, c(try_mean, try_size), iterlim=1000, print.level=this.print.level)) )
+ 
+   nb_fit_mu = nb_fit$estimate[1];
+   nb_fit_size = nb_fit$estimate[2];
+ 
+   cat("Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, "\n")
+   
+   if (try_size <= 0.001) {
+     try_size = 100000
+     try_means_index = try_means_index + 1
+   }
+ }
Try Mean:  1.712466  Size:  10000 
1   5 
1.712466   10000 
1   5 
1.712466   10000 
1   5 
1.712467   10000 
1   5 
1.712466   10000.01 
1   5 
1.632014   10000 
1   5 
1.632016   10000 
1   5 
1.632014   10000.01 
1   5 
1.08538   10000 
1   5 
1.085381   10000 
1   5 
1.08538   10000.01 
1   5 
1.314287   10000 
1   5 
1.314288   10000 
1   5 
1.314287   10000.01 
1   5 
1.268594   10000 
1   5 
1.268595   10000 
1   5 
1.268594   10000.01 
1   5 
1.261587   10000 
1   5 
1.261589   10000 
1   5 
1.261587   10000.01 
1   5 
1.261863   10000 
1   5 
1.261864   10000 
1   5 
1.261863   10000.01 
1   5 
1.261861   10000 
1   5 
1.261862   10000 
1   5 
1.261861   10000.01 
1   5 
1.261861   10000 
1   5 
1.261862   10000 
1   5 
1.261861   10000.01 
Fit Mean:  1.261861  Size:  10000  Code:  2 
Try Mean:  1.712466  Size:  1000 
1   5 
1.712466   1000 
1   5 
1.712466   1000 
1   5 
1.712467   1000 
1   5 
1.712466   1000.001 
1   5 
1.632126   1000 
1   5 
1.632128   1000 
1   5 
1.632126   1000.001 
1   5 
1.084524   1000 
1   5 
1.084525   1000 
1   5 
1.084524   1000.001 
1   5 
1.314397   1000 
1   5 
1.314398   1000 
1   5 
1.314397   1000.001 
1   5 
1.268459   1000 
1   5 
1.26846   1000 
1   5 
1.268459   1000.001 
1   5 
1.261371   1000 
1   5 
1.261372   1000 
1   5 
1.261371   1000.001 
1   5 
1.261651   1000 
1   5 
1.261653   1000 
1   5 
1.261651   1000.001 
1   5 
1.26165   1000 
1   5 
1.261651   1000 
1   5 
1.26165   1000.001 
1   5 
1.26165   1000 
1   5 
1.261651   1000 
1   5 
1.26165   1000.001 
Fit Mean:  1.26165  Size:  1000  Code:  2 
Try Mean:  1.712466  Size:  100 
1   5 
1.712466   100 
1   5 
1.712466   100 
1   5 
1.712467   100 
1   5 
1.712466   100.0001 
1   5 
1.633224   100 
1   5 
1.633225   100 
1   5 
1.633224   100.0001 
1   5 
1.075868   100.0001 
1   5 
1.075869   100.0001 
1   5 
1.075868   100.0002 
1   5 
1.315557   100 
1   5 
1.315559   100 
1   5 
1.315557   100.0001 
1   5 
1.267143   100 
1   5 
1.267145   100 
1   5 
1.267143   100.0001 
1   5 
1.259188   100.0001 
1   5 
1.259189   100.0001 
1   5 
1.259188   100.0002 
1   5 
1.259528   100.0001 
1   5 
1.259529   100.0001 
1   5 
1.259528   100.0002 
1   5 
1.259526   100.0001 
1   5 
1.259528   100.0001 
1   5 
1.259526   100.0002 
1   5 
1.259483   100.0007 
1   5 
1.259484   100.0007 
1   5 
1.259483   100.0008 
1   5 
1.259437   100.002 
1   5 
1.259438   100.002 
1   5 
1.259437   100.0021 
1   5 
1.259348   100.0065 
1   5 
1.259349   100.0065 
1   5 
1.259348   100.0066 
1   5 
1.259213   100.0181 
1   5 
1.259214   100.0181 
1   5 
1.259213   100.0182 
1   5 
1.25899   100.0503 
1   5 
1.258991   100.0503 
1   5 
1.25899   100.0504 
1   5 
1.258633   100.1353 
1   5 
1.258635   100.1353 
1   5 
1.258633   100.1354 
1   5 
1.258061   100.3606 
1   5 
1.258062   100.3606 
1   5 
1.258061   100.3607 
1   5 
1.257158   100.9488 
1   5 
1.257159   100.9488 
1   5 
1.257158   100.9489 
1   5 
1.255773   102.4629 
1   5 
1.255775   102.4629 
1   5 
1.255773   102.463 
1   5 
1.253807   106.2352 
1   5 
1.253808   106.2352 
1   5 
1.253807   106.2353 
1   5 
1.251466   115.0945 
1   5 
1.251468   115.0945 
1   5 
1.251466   115.0946 
1   5 
1.24973   134.2898 
1   5 
1.249732   134.2898 
1   5 
1.24973   134.2899 
1   5 
1.250624   172.5311 
1   5 
1.250625   172.5311 
1   5 
1.250624   172.5312 
1   5 
1.255708   236.5459 
1   5 
1.255709   236.5459 
1   5 
1.255708   236.5461 
1   5 
1.261493   311.2936 
1   5 
1.261495   311.2936 
1   5 
1.261493   311.2939 
1   5 
1.264469   376.9723 
1   5 
1.264471   376.9723 
1   5 
1.264469   376.9727 
1   5 
1.265751   456.4603 
1   5 
1.265753   456.4603 
1   5 
1.265751   456.4608 
1   5 
1.265514   590.9755 
1   5 
1.265516   590.9755 
1   5 
1.265514   590.9761 
1   5 
1.263562   791.4306 
1   5 
1.263563   791.4306 
1   5 
1.263562   791.4314 
1   5 
1.261446   1033.928 
1   5 
1.261447   1033.928 
1   5 
1.261446   1033.929 
1   5 
1.260305   1299.834 
1   5 
1.260306   1299.834 
1   5 
1.260305   1299.835 
1   5 
1.260008   1660.989 
1   5 
1.260009   1660.989 
1   5 
1.260008   1660.991 
1   5 
1.260548   2205.927 
1   5 
1.260549   2205.927 
1   5 
1.260548   2205.929 
1   5 
1.261539   2940.206 
1   5 
1.26154   2940.206 
1   5 
1.261539   2940.209 
1   5 
1.262298   3806.852 
1   5 
1.2623   3806.852 
1   5 
1.262298   3806.856 
1   5 
1.262636   4885.015 
1   5 
1.262637   4885.015 
1   5 
1.262636   4885.02 
1   5 
1.262567   6406.798 
1   5 
1.262568   6406.798 
1   5 
1.262567   6406.805 
1   5 
1.262188   8538.721 
1   5 
1.26219   8538.721 
1   5 
1.262188   8538.73 
1   5 
1.261783   11258.72 
1   5 
1.261784   11258.72 
1   5 
1.261783   11258.73 
1   5 
1.261558   14524.86 
1   5 
1.261559   14524.86 
1   5 
1.261558   14524.88 
1   5 
1.261528   18924.94 
1   5 
1.26153   18924.94 
1   5 
1.261528   18924.96 
1   5 
1.261663   25716.29 
1   5 
1.261664   25716.29 
1   5 
1.261663   25716.31 
1   5 
1.261848   33667.64 
1   5 
1.261849   33667.64 
1   5 
1.261848   33667.67 
1   5 
1.261974   42529.87 
1   5 
1.261975   42529.87 
1   5 
1.261974   42529.91 
1   5 
1.262051   57561.93 
1   5 
1.262052   57561.93 
1   5 
1.262051   57561.99 
1   5 
1.26204   79791.34 
1   5 
1.262042   79791.34 
1   5 
1.26204   79791.42 
1   5 
1.261963   100496.1 
1   5 
1.261964   100496.1 
1   5 
1.261963   100496.2 
1   5 
1.261909   108427.5 
1   5 
1.261911   108427.5 
1   5 
1.261909   108427.6 
1   5 
1.26186   126957.2 
1   5 
1.261862   126957.2 
1   5 
1.26186   126957.3 
1   5 
1.261874   124546.9 
1   5 
1.261862   126696 
1   5 
1.261861   126930.7 
1   5 
1.26186   126954.5 
1   5 
1.26186   126956.9 
1   5 
1.26186   126957.1 
1   5 
1.261987   126957.2 
1   5 
1.261734   126957.2 
1   5 
1.26186   126969.9 
1   5 
1.26186   126944.5 
1   5 
1.261858   136522.3 
1   5 
1.261984   136522.3 
1   5 
1.261732   136522.3 
1   5 
1.261858   136535.9 
1   5 
1.261858   136508.6 
1   5 
1.261862   196875.3 
1   5 
1.261988   196875.3 
1   5 
1.261736   196875.3 
1   5 
1.261862   196895 
1   5 
1.261862   196855.6 
1   5 
1.261875   253812.8 
1   5 
1.262001   253812.8 
1   5 
1.261749   253812.8 
1   5 
1.261875   253838.1 
1   5 
1.261875   253787.4 
1   5 
1.261889   338024.8 
1   5 
1.262016   338024.8 
1   5 
1.261763   338024.8 
1   5 
1.261889   338058.6 
1   5 
1.261889   337991 
1   5 
1.261897   438039.5 
1   5 
1.262023   438039.5 
1   5 
1.26177   438039.5 
1   5 
1.261897   438083.3 
1   5 
1.261897   437995.7 
1   5 
1.261897   538054.1 
1   5 
1.262023   538054.1 
1   5 
1.261771   538054.1 
1   5 
1.261897   538107.9 
1   5 
1.261897   538000.3 
1   5 
1.261894   638068.8 
1   5 
1.26202   638068.8 
1   5 
1.261767   638068.8 
1   5 
1.261894   638132.6 
1   5 
1.261894   638005 
1   5 
1.261891   738083.5 
1   5 
1.262017   738083.5 
1   5 
1.261764   738083.5 
1   5 
1.261891   738157.3 
1   5 
1.261891   738009.6 
1   5 
1.261887   838098.1 
1   5 
1.262014   838098.1 
1   5 
1.261761   838098.1 
1   5 
1.261887   838181.9 
1   5 
1.261887   838014.3 
Fit Mean:  1.261887  Size:  838098.1  Code:  1 
> 
> cat("Final Fit Mean: ", nb_fit_mu, " Size: ", nb_fit_size, " Code: ", nb_fit$code, " Try Size: ", try_size, "\n")
Final Fit Mean:  1.261887  Size:  838098.1  Code:  1  Try Size:  100 
> 
> ## Fit failed = reset parameters so graphing and output code can recognize this
> if ((nb_fit_mu < 0) || (nb_fit_size < 0) || (nb_fit$code != 1))
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> 
> ## things can go wrong with fitting and we can still end up with invalid values
> 
> fit_nb = c()
> included_fract = 0
> if (nb_fit_mu > 0)
+ {
+   end_fract = pnbinom(end_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   start_fract = pnbinom(start_i_for_fits, mu = nb_fit_mu, size=nb_fit_size)
+   included_fract = end_fract-start_fract;
+ 
+   if (included_fract >= 0.01) {
+ 
+     ## Adjust so that we are back in full coords before making fit!!
+     if (num_per_bin > 1) 
+     {
+       nb_fit_mu = nb_fit_mu * num_per_bin
+     }
+     fit_nb = dnbinom(0:max(X$coverage), mu = nb_fit_mu, size=nb_fit_size)*inner_total/included_fract;
+   }
+ }
> 
> ## If an insufficient amount of fit was included, then invalidate it
> if (included_fract < 0.01)
+ {
+   nb_fit_mu = 0
+   nb_fit_size = 0
+ }
> 
> f_p <- function(par) {
+ 
+   lambda = par[1];
+ 
+   if (lambda <= 0)
+   {
+     return(0);
+   }
+   
+ 	total <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{	
+     #cat(i, " ", lambda, "\n");
+ 		dist[i] <- dpois(i, lambda=lambda);
+ 		total <- total + dist[i] 
+ 	}
+ 	#print (total)
+ 
+  	l <- 0;
+ 	for (i in start_i_for_fits:end_i_for_fits)
+ 	{
+ 		l <- l + ((X.for.fits[i]/inner_total)-(dist[i]/total))^2;
+ 	}
+ 	return(l);
+ }
> 
> 
> ## Fit Poisson 
> ## - allow fit to fail and set all params to zero/empty if that is the case
> 
> p_fit = NULL
> try(suppressWarnings(p_fit<-nlm(f_p, c(m), print.level=this.print.level)))
> 
> fit_p = c()
> if (!is.null(p_fit) && (p_fit$estimate[1] > 0))
+ {
+   #print (nb_fit$estimate[1])
+   p_fit_lambda = p_fit$estimate[1];
+   #print(0:max(X$coverage))
+ 
+   end_fract = ppois(end_i_for_fits, lambda = p_fit_lambda)
+   start_fract = ppois(start_i_for_fits, lambda = p_fit_lambda)
+   included_fract = end_fract-start_fract;
+ 
+   ## Adjust so that we are back in full coords before making fit!!
+   if (num_per_bin > 1) 
+   {
+     p_fit_lambda = p_fit_lambda * num_per_bin
+   }
+   fit_p<-dpois(0:max(X$coverage), lambda = p_fit_lambda)*inner_total/included_fract;
+ }
> 
> 
> ## Graphing
> ##
> ## don't graph very high values with very little coverage
> i<-max_i
> while (i <= length(X$n) && X$n[i]>0.01*max_n)
+ {		
+ 	i <- i+1;
+ }
> graph_end_i <-i
> 
> ## Ths leaves enough room to the right of the peak for the legend
> graph_end_i = max(floor(2.2 * max_i), graph_end_i);
> 
> ## graphics settings
> my_pch = 21
> my_col = "black";
> my_col_censored = "red";
> 
> if (pdf_output == 0) {
+   
+   ## bitmap() requires ghostscript to be installed.
+   ## taa=4, gaa=2 options NOT compatible with earlier R versions!
+   ## units = "px" NOT compatible with even earlier R versions!
+   
+   if(!capabilities(what = "png"))
+   {
+     ## fallback to ghostscript
+     bitmap(plot_file, height=6, width=7, type = "png16m", res = 72, pointsize=18)
+   } else {
+     ## use X11 function, which gives better resolution
+     png(plot_file, height=6, width=7, units ="in", res = 72, pointsize=18)
+     par(family="sans")
+   }
+ } else {
+   pdf(plot_file, height=6, width=7)
+   par(family="sans")
+ }
> 
> par(mar=c(5.5,7.5,3,1.5));
> 
> max_y = 0
> if (plot_poisson) {
+ 	max_y = max(X$n, fit_p, fit_nb)
+ } else {
+ 	max_y = max(X$n, fit_nb)
+ }
> 
> plot(0:10, 0:10, type="n", lty="solid", ylim=c(0, max_y)*1.05, xlim=c(0, graph_end_i), lwd=1, xaxs="i", yaxs="i", axes=F, las=1, main="Coverage Distribution at Unique-Only Positions", xlab="Coverage depth (reads)", ylab="", cex.lab=1.2, cex.axis=1.2)
> 
> mtext(side = 2, text = "Number of reference positions", line = 5.5, cex=1.2)
> 
> sciNotation <- function(x, digits = 1) {
+     if (length(x) > 1) {
+         return(append(sciNotation(x[1]), sciNotation(x[-1])))     
+ 	} 
+     if (!x) return(0) 
+ 
+ 	exponent <- floor(log10(x)) 
+     base <- round(x / 10^exponent, digits)     
+ 	as.expression(substitute(base %*% 10^exponent, list(base = base, exponent = exponent))) 
+ }
> 
> #axis(2, cex.lab=1.2, las=1, cex.axis=1.2, labels=T, at=(0:6)*50000)
> axis(2, cex.lab=1.2, las=1, cex.axis=1.2, at = axTicks(2), labels = sciNotation(axTicks(2), 1))
> axis(1, cex.lab=1.2, cex.axis=1.2, labels=T)
> box()
> 
> #graph the coverage as points
> fit_data <- subset(X, (coverage>=start_i) & (coverage<=end_i) );
> points(fit_data$coverage, fit_data$n, pch=my_pch, col=my_col, bg="white", cex=1.2)
> 
> #graph the censored coverage as red points
> cat(start_i, " ", end_i, "\n", sep="")
1 5
> 
> censored_data <- subset(X, (coverage<start_i) | (coverage>end_i) );
> points(censored_data$coverage, censored_data$n, pch=my_pch, col=my_col_censored, bg="white", cex=1.2)
> 
> #graph the poisson fit IF REQUESTED
> if (plot_poisson) {
+ 	lines(0:max(X$coverage), fit_p, lwd=3, lty="22", col="black");
+ }
> 
> #graph the negative binomial fit
> if (nb_fit_mu > 0) {
+   lines(0:max(X$coverage), fit_nb, lwd=3, col="black");
+ }
> 
> if (plot_poisson) {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial", "Poisson"), lty=c("blank","blank","solid","22"), lwd=c(1,1,2,2), pch=c(my_pch, my_pch, -1, -1), col=c("black", "red", "black", "black"), bty="n")
+ } else {
+ 	legend("topright", c("Coverage distribution", "Censored data", "Negative binomial"), lty=c("blank","blank","solid"), lwd=c(1,1,2), pch=c(my_pch, my_pch, -1), col=c("black", "red", "black"), bty="n")
+ }
> 
> dev.off()
null device 
          1 
> 
> ## Fit the marginal value that we use for propagating deletions
> 
> if (nb_fit_mu > 0) {
+   cat(nb_fit_size, " ", nb_fit_mu, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = nb_fit_size, mu = nb_fit_mu))
+ } else {
+   cat("Fallback to calculating off an estimate of just variance = mu + mu^2/size\n")
+   size_estimate = (1/(v-m))*(m*m)
+   cat("Mu estimate=", m," Size estimate =", size_estimate, "\n")
+   deletion_propagation_coverage = suppressWarnings(qnbinom(deletion_propagation_pr_cutoff, size = size_estimate, mu = m))
+   if (is.na(deletion_propagation_coverage) || is.nan(deletion_propagation_coverage) || (deletion_propagation_coverage < 1)) {
+     cat("Double fallback to calculating as just 10% of the mean\n")
+     deletion_propagation_coverage = m * 0.1
+   }
+ }
838098.1   1.261887 
> 
> #Don't allow one read to indicate non-deleted regions
> if (deletion_propagation_coverage < 1) {
+     deletion_propagation_coverage = 1
+ }
> 
> #This works fine with the negative values
> #If we have both low fit coverage and low straight average coverage then we're deleted...
> if ( (nb_fit_mu <= 3) && (m <= 3) ) {
+   deletion_propagation_coverage = -1
+ }
> 
> #print out statistics
> 
> print(nb_fit_size);
[1] 838098.1
> print(nb_fit_mu);
[1] 1.261887
> 
> print(m)
[1] 1.746284
> print(v)
[1] 0.8780771
> print(D)
[1] 0.5028261
> 
> print(deletion_propagation_coverage)
[1] -1
> 
> warnings()
> 
